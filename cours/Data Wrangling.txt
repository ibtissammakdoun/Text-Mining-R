To start, we import the tm package in R for use in this course. Now, we create a raw course corpus by loading the contents of the courses directory into a VCorpus variable. Next, we perform a series of cleansing steps. If you are unfamiliar with these steps, check out the Processing Text with R Training on LinkedIn Learning. We first convert the corpus into lowercase using the tm_map function. Then we remove punctuations. Stopwords removal is done using the standard stopwords list. Finally, we convert the corpus into a document term matrix using the function DocumentTermMatrix. Let's execute the code and review the results. We see that the documents as rows and each unique term as columns in the matrix. The matrix only has term frequency, so it shows the count of these terms in each document. For word cloud, we look at the most popular words across all documents. So, we need to aggregate counts by terms. We do so using the colSums function and then sorted in descending order. Finally, we convert the word frequency into a DataFrame. Let's execute this code and save the contents of the DataFrame. 